#!/usr/bin/env python3
"""
Skill Evolution Framework
Autonomous skill creation, editing, and evaluation for AI agents
"""

import os
import json
import pickle
from datetime import datetime
from typing import Dict, List, Any, Optional
import hashlib

class SkillEvolutionAgent:
    """
    Autonomous skill evolution through meta-learning and pattern extraction.
    
    Enables agents to:
    1. Track execution performance
    2. Extract successful patterns
    3. Evolve skills based on performance data
    4. Share patterns across agents
    """
    
    def __init__(self, agent_id: str, skill_dir: str, data_dir: Optional[str] = None):
        """
        Initialize Skill Evolution Agent.
        
        Args:
            agent_id: Unique identifier for the agent
            skill_dir: Directory containing skill files
            data_dir: Directory for storing evolution data (defaults to skill_dir/evolution)
        """
        self.agent_id = agent_id
        self.skill_dir = skill_dir
        
        if data_dir is None:
            data_dir = os.path.join(skill_dir, "evolution")
        self.data_dir = data_dir
        
        # Create directories if they don't exist
        os.makedirs(self.data_dir, exist_ok=True)
        os.makedirs(os.path.join(self.data_dir, "patterns"), exist_ok=True)
        os.makedirs(os.path.join(self.data_dir, "history"), exist_ok=True)
        
        # Load existing data
        self.skill_history = self._load_data("skill_history", [])
        self.execution_results = self._load_data("execution_results", [])
        self.pattern_library = self._load_data("pattern_library", [])
        
        # Performance tracking
        self.metrics_tracker = PerformanceTracker()
        
    def _load_data(self, data_name: str, default: Any) -> Any:
        """Load persisted data from disk"""
        file_path = os.path.join(self.data_dir, f"{data_name}.json")
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r') as f:
                    return json.load(f)
            except:
                return default
        return default
    
    def _save_data(self, data_name: str, data: Any):
        """Save data to disk"""
        file_path = os.path.join(self.data_dir, f"{data_name}.json")
        with open(file_path, 'w') as f:
            json.dump(data, f, indent=2, default=str)
    
    def track_execution(self, skill_name: str, inputs: Dict, outputs: Dict, 
                       metrics: Dict[str, float]) -> Dict:
        """
        Record skill execution for learning and pattern extraction.
        
        Args:
            skill_name: Name of the skill executed
            inputs: Input parameters to the skill
            outputs: Outputs generated by the skill
            metrics: Performance metrics (e.g., accuracy, speed, success)
            
        Returns:
            Execution record with success score
        """
        # Calculate success score
        success_score = self.metrics_tracker.calculate_success_score(
            self.agent_id, metrics
        )
        
        # Create execution record
        record = {
            'timestamp': datetime.now().isoformat(),
            'agent_id': self.agent_id,
            'skill': skill_name,
            'inputs': inputs,
            'outputs': outputs,
            'metrics': metrics,
            'success_score': success_score,
            'execution_id': self._generate_execution_id(skill_name, inputs)
        }
        
        # Add to execution results
        self.execution_results.append(record)
        
        # Save to disk
        self._save_data("execution_results", self.execution_results)
        
        # Extract patterns if successful
        if success_score >= 0.7:  # Threshold for pattern extraction
            self._extract_and_store_pattern(record)
        
        return record
    
    def _generate_execution_id(self, skill_name: str, inputs: Dict) -> str:
        """Generate unique ID for execution"""
        input_str = json.dumps(inputs, sort_keys=True)
        hash_input = f"{skill_name}:{input_str}"
        return hashlib.md5(hash_input.encode()).hexdigest()[:12]
    
    def _extract_and_store_pattern(self, execution_record: Dict):
        """Extract pattern from successful execution"""
        pattern = {
            'pattern_id': self._generate_pattern_id(execution_record),
            'agent_id': self.agent_id,
            'skill': execution_record['skill'],
            'context': self._extract_context(execution_record['inputs']),
            'strategy': self._extract_strategy(execution_record),
            'success_score': execution_record['success_score'],
            'timestamp': execution_record['timestamp'],
            'frequency': 1,
            'metrics': execution_record['metrics']
        }
        
        # Check for similar patterns
        similar_pattern = self._find_similar_pattern(pattern)
        if similar_pattern:
            # Update existing pattern
            similar_pattern['frequency'] += 1
            similar_pattern['success_score'] = max(
                similar_pattern['success_score'],
                pattern['success_score']
            )
            # Update strategy with new insights
            similar_pattern['strategy'] = self._merge_strategies(
                similar_pattern['strategy'],
                pattern['strategy']
            )
        else:
            # Add new pattern
            self.pattern_library.append(pattern)
        
        # Save updated pattern library
        self._save_data("pattern_library", self.pattern_library)
        
        # Also save individual pattern file
        pattern_file = os.path.join(
            self.data_dir, 
            "patterns", 
            f"{pattern['pattern_id']}.json"
        )
        with open(pattern_file, 'w') as f:
            json.dump(pattern, f, indent=2)
    
    def _generate_pattern_id(self, execution_record: Dict) -> str:
        """Generate unique pattern ID"""
        skill = execution_record['skill']
        context_hash = hashlib.md5(
            json.dumps(execution_record['inputs'], sort_keys=True).encode()
        ).hexdigest()[:8]
        return f"{skill}_{context_hash}"
    
    def _extract_context(self, inputs: Dict) -> Dict:
        """Extract relevant context from inputs"""
        # Simplified context extraction - can be customized per agent
        context = {
            'input_keys': list(inputs.keys()),
            'input_types': {k: type(v).__name__ for k, v in inputs.items()},
            'complexity': len(str(inputs))
        }
        return context
    
    def _extract_strategy(self, execution_record: Dict) -> Dict:
        """Extract strategy from execution"""
        # This is a simplified version - should be customized per agent type
        strategy = {
            'approach': 'standard',
            'steps': len(execution_record['outputs']) if isinstance(execution_record['outputs'], dict) else 1,
            'decision_count': self._count_decisions(execution_record),
            'adaptations': []
        }
        return strategy
    
    def _count_decisions(self, execution_record: Dict) -> int:
        """Count decision points in execution"""
        # Simplified - should be customized
        outputs = execution_record['outputs']
        if isinstance(outputs, dict):
            return len([v for v in outputs.values() if isinstance(v, (bool, int, float))])
        return 1
    
    def _merge_strategies(self, strategy1: Dict, strategy2: Dict) -> Dict:
        """Merge two strategies"""
        merged = strategy1.copy()
        merged['frequency'] = strategy1.get('frequency', 1) + 1
        return merged
    
    def _find_similar_pattern(self, new_pattern: Dict) -> Optional[Dict]:
        """Find similar pattern in library"""
        for pattern in self.pattern_library:
            if self._patterns_similar(pattern, new_pattern):
                return pattern
        return None
    
    def _patterns_similar(self, pattern1: Dict, pattern2: Dict) -> bool:
        """Check if two patterns are similar"""
        # Same skill and similar context
        if pattern1['skill'] != pattern2['skill']:
            return False
        
        # Check context similarity
        context1 = pattern1['context']
        context2 = pattern2['context']
        
        # Simplified similarity check
        key_overlap = len(set(context1.get('input_keys', [])) & 
                         set(context2.get('input_keys', [])))
        total_keys = len(set(context1.get('input_keys', [])) | 
                        set(context2.get('input_keys', [])))
        
        return key_overlap / max(total_keys, 1) > 0.6
    
    def get_successful_patterns(self, skill_name: Optional[str] = None, 
                               min_success: float = 0.7) -> List[Dict]:
        """
        Get successful patterns for a skill or all skills.
        
        Args:
            skill_name: Filter by skill name (None for all skills)
            min_success: Minimum success score threshold
            
        Returns:
            List of successful patterns
        """
        patterns = self.pattern_library
        
        if skill_name:
            patterns = [p for p in patterns if p['skill'] == skill_name]
        
        patterns = [p for p in patterns if p['success_score'] >= min_success]
        
        # Sort by success score and frequency
        patterns.sort(key=lambda x: (x['success_score'], x['frequency']), reverse=True)
        
        return patterns
    
    def evolve_skill(self, skill_name: str, performance_data: Optional[List[Dict]] = None) -> str:
        """
        Generate evolved version of a skill based on performance data.
        
        Args:
            skill_name: Name of skill to evolve
            performance_data: Optional specific performance data to use
            
        Returns:
            Path to evolved skill file
        """
        if performance_data is None:
            # Get all execution results for this skill
            performance_data = [
                r for r in self.execution_results 
                if r['skill'] == skill_name
            ]
        
        # Get successful patterns for this skill
        successful_patterns = self.get_successful_patterns(skill_name, min_success=0.7)
        
        # Load current skill content
        current_skill_path = os.path.join(self.skill_dir, f"{skill_name}.md")
        if not os.path.exists(current_skill_path):
            current_skill_path = os.path.join(self.skill_dir, "SKILL.md")
        
        if not os.path.exists(current_skill_path):
            raise FileNotFoundError(f"Skill file not found: {skill_name}")
        
        with open(current_skill_path, 'r') as f:
            current_content = f.read()
        
        # Generate evolved content
        skill_refiner = SkillRefiner()
        evolved_content = skill_refiner.refine_skill_content(
            skill_name=skill_name,
            current_content=current_content,
            patterns=successful_patterns,
            performance_data=performance_data,
            agent_id=self.agent_id
        )
        
        # Create new version
        version = self._create_skill_version(skill_name, evolved_content)
        
        # Track evolution
        evolution_record = {
            'skill': skill_name,
            'version': version,
            'timestamp': datetime.now().isoformat(),
            'parent_version': self._get_current_version(skill_name),
            'patterns_used': [p['pattern_id'] for p in successful_patterns],
            'performance_basis': [r['execution_id'] for r in performance_data]
        }
        
        self.skill_history.append(evolution_record)
        self._save_data("skill_history", self.skill_history)
        
        return version
    
    def _create_skill_version(self, skill_name: str, content: str) -> str:
        """Create new version of skill file"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        version_id = f"{skill_name}_v{timestamp}"
        
        version_dir = os.path.join(self.data_dir, "versions")
        os.makedirs(version_dir, exist_ok=True)
        
        version_path = os.path.join(version_dir, f"{version_id}.md")
        with open(version_path, 'w') as f:
            f.write(content)
        
        return version_path
    
    def _get_current_version(self, skill_name: str) -> Optional[str]:
        """Get current version of skill"""
        skill_path = os.path.join(self.skill_dir, f"{skill_name}.md")
        if os.path.exists(skill_path):
            return skill_path
        return None
    
    def share_patterns(self, other_agent: 'SkillEvolutionAgent', 
                      pattern_ids: Optional[List[str]] = None) -> int:
        """
        Share patterns with another agent.
        
        Args:
            other_agent: Target SkillEvolutionAgent
            pattern_ids: Specific patterns to share (None for top patterns)
            
        Returns:
            Number of patterns shared
        """
        if pattern_ids is None:
            # Share top 5 patterns
            patterns_to_share = self.get_successful_patterns(min_success=0.8)[:5]
        else:
            patterns_to_share = [
                p for p in self.pattern_library 
                if p['pattern_id'] in pattern_ids
            ]
        
        shared_count = other_agent.receive_patterns(patterns_to_share)
        return shared_count
    
    def receive_patterns(self, patterns: List[Dict]) -> int:
        """
        Receive patterns from another agent.
        
        Args:
            patterns: Patterns to receive
            
        Returns:
            Number of new patterns added
        """
        added_count = 0
        
        for pattern in patterns:
            # Check if similar pattern exists
            existing = self._find_similar_pattern(pattern)
            if existing:
                # Update existing pattern
                existing['frequency'] += 1
                existing['success_score'] = max(
                    existing['success_score'],
                    pattern['success_score']
                )
                # Mark as cross-agent pattern
                if 'source_agents' not in existing:
                    existing['source_agents'] = []
                if pattern['agent_id'] not in existing['source_agents']:
                    existing['source_agents'].append(pattern['agent_id'])
            else:
                # Add new pattern with source annotation
                pattern['source_agents'] = [pattern['agent_id']]
                self.pattern_library.append(pattern)
                added_count += 1
        
        if added_count > 0:
            self._save_data("pattern_library", self.pattern_library)
        
        return added_count
    
    def get_evolution_report(self) -> Dict:
        """Generate evolution progress report"""
        return {
            'agent_id': self.agent_id,
            'total_executions': len(self.execution_results),
            'successful_executions': len([r for r in self.execution_results 
                                         if r['success_score'] >= 0.7]),
            'patterns_extracted': len(self.pattern_library),
            'skills_evolved': len(self.skill_history),
            'avg_success_score': (
                sum(r['success_score'] for r in self.execution_results) / 
                max(len(self.execution_results), 1)
            ),
            'top_skills': self._get_top_skills(),
            'recent_evolutions': self.skill_history[-5:] if self.skill_history else []
        }
    
    def _get_top_skills(self) -> List[Dict]:
        """Get top performing skills"""
        skill_performance = {}
        
        for record in self.execution_results:
            skill = record['skill']
            if skill not in skill_performance:
                skill_performance[skill] = {
                    'count': 0,
                    'total_score': 0,
                    'last_executed': record['timestamp']
                }
            
            skill_performance[skill]['count'] += 1
            skill_performance[skill]['total_score'] += record['success_score']
        
        # Calculate averages and sort
        top_skills = []
        for skill, data in skill_performance.items():
            avg_score = data['total_score'] / data['count']
            top_skills.append({
                'skill': skill,
                'execution_count': data['count'],
                'avg_success_score': avg_score,
                'last_executed': data['last_executed']
            })
        
        top_skills.sort(key=lambda x: x['avg_success_score'], reverse=True)
        return top_skills[:5]


class PerformanceTracker:
    """Standardized performance tracking across agent types"""
    
    # Metric templates for different agent types
    METRIC_TEMPLATES = {
        'trade-recommender': {
            'win_rate': {'weight': 0.3, 'normalize': lambda x: x / 100},
            'avg_return': {'weight': 0.25, 'normalize': lambda x: min(x / 10, 1.0)},
            'sharpe_ratio': {'weight': 0.2, 'normalize': lambda x: min(x / 2, 1.0)},
            'max_drawdown': {'weight': 0.15, 'normalize': lambda x: 1.0 - min(x / 50, 1.0)},
            'execution_speed': {'weight': 0.1, 'normalize': lambda x: min(10 / x, 1.0)}
        },
        'roi-analyst': {
            'accuracy': {'weight': 0.4, 'normalize': lambda x: x / 100},
            'completeness': {'weight': 0.25, 'normalize': lambda x: x / 100},
            'actionability': {'weight': 0.2, 'normalize': lambda x: x / 100},
            'time_to_insight': {'weight': 0.15, 'normalize': lambda x: min(60 / x, 1.0)}
        },
        'lead-generator': {
            'response_rate': {'weight': 0.3, 'normalize': lambda x: x / 100},
            'conversion_rate': {'weight': 0.25, 'normalize': lambda x: x / 100},
            'lead_quality': {'weight': 0.25, 'normalize': lambda x: x / 100},
            'enrichment_accuracy': {'weight': 0.2, 'normalize': lambda x: x / 100}
        }
    }
    
    def calculate_success_score(self, agent_id: str, metrics: Dict[str, float